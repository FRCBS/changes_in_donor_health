---
title: "Inital data analysis for FINDONOR- CHANGES IN SELF-RATED HEALTH DURING THE STUDY AND IT'S RELATION TO IRON BIOMARKERS "
author: "Mikko Arvas"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---


```{r setup, include=FALSE}
# echo "rmarkdown::render('inital_data_analysis.Rmd', clean=TRUE,output_format='html_document',output_file='../results/inital_data_analysis.html')" | R --slave
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
library(tidyverse)
library(corrplot)
#library(epitools)
#library(ez)
library(lubridate)
#library(ggbeeswarm)
#library(tidymodels)
#library(broom)
#library(GGally)
#library(ggfortify)
#library(car)
#library(boot)
```

# Executive summary


In this file we carry out inital data analysis to decide which explenatory variables to exclude based on correlations between the explenatory variables and counts is missing data.

# Load the data

We load the data and assign groups as they were assigned in the first part of the study. 

```{r loading}
#Load questionnaire data
load(file = "../data/final_data.rdata") 

data %>% group_by(questionnaire) %>% count()

```

```{r}
data %>% group_by(questionnaire,group) %>% filter(group != 'Women_pre_menop_no_mens') %>%  count()
```


#Remove end point variable

In the inital data analysis stage we do not want to look at our primary endpoint: "self-rated health" i.e. "health" to avoid fishing for correlations.
```{r}

data <- data %>% filter(!is.na(health))  %>% select(-health)
data %>% group_by(questionnaire) %>% count()
```


#Recodings
Questions with 3 possible answers : "no", "yes", "don't know", are recoded as an ordered factor with 3 levels: "yes"< "don't know" <  "no".  
```{r}
#Have you felt that you were able to accomplish less than you would have liked to?
temp <- as.character(data$accomplish)
temp[is.na(temp)] <- "don't know"
data$accomplish = ordered(temp,
                levels =  c("yes","don't know", "no"))
#During the past four weeks, has your mental health interfered with your work or other daily activities?
temp <- as.character(data$ment_inf)
temp[is.na(temp)] <- "don't know"
data$ment_inf = ordered(temp,
                levels =  c("yes","don't know", "no"))

#During the past four weeks, have your physical symptoms (such as pain) or health in general interfered with your work or other daily activities?
temp <- as.character(data$phys_inf)
temp[is.na(temp)] <- "don't know"
data$phys_inf = ordered(temp,
                levels =  c("yes","don't know", "no"))



```



# How much data do we have
```{r}
#drop out variables that, 
# we know from our previous work are too messy: iron_supp_detailed
# were only asked in second questionaire: life_qual, education, employment
# are conveniency variables: AgeGroup, SixMonthsFromStartCount_FB, TwoYearsFromStartCount_FB
# is ID: donor
temp <- data %>% select(-iron_supp_detailed, -life_qual, -education, -employment,-AgeGroup, -SixMonthsFromStartCount_FB,-TwoYearsFromStartCount_FB,-donor)
temp <- na.omit(temp)
temp %>% group_by(questionnaire) %>% count()
```

From `r ncol(temp)` questions.

As we will loose one third of our data if we study only complete data we have try to make decisions on which questions to exclude prior to analyses or which data to impute.

```{r}
temp <- data %>% select(-iron_supp_detailed, -life_qual, -education, -employment,-AgeGroup, -SixMonthsFromStartCount_FB,-TwoYearsFromStartCount_FB,-donor)
temp <- temp %>% group_by(questionnaire) %>%  summarise_all(funs(sum(is.na(.))))
temp <- as_tibble(t(temp), rownames = "Variable") %>% filter(Variable != "questionnaire")
colnames(temp)[2] <- "First"
colnames(temp)[3] <- "Second"
temp <- temp %>%  gather(key="questionnaire",value="NAs",-Variable) %>% mutate(NAs = as.numeric(gsub(" ","",NAs))) %>% filter(NAs != 0)

ggplot(temp) + geom_col(aes(x=Variable,y=NAs,fill=questionnaire),pos="dodge") +  coord_flip() 

```



```{r}
temp <- temp %>% arrange(NAs) %>% tail(10)

ggplot(temp) + geom_col(aes(x=Variable,y=NAs,fill=questionnaire),pos="dodge") +  coord_flip() 

```

People cannot remember if they have taken vitamine supplements containing iron or vitamine C. Let's first see if some of these will drop out because they correlate heavily with some other explenatory variable.

# Correlations between variables

```{r , warning=FALSE}

temp <- data %>% select(-iron_supp_detailed, -life_qual, -education, -employment,-AgeGroup, -SixMonthsFromStartCount_FB,-TwoYearsFromStartCount_FB, -donor,-questionnaire,-sex,-group)
temp$date <- as.numeric(temp$date)

#Change the numeric to factors to enable similar correlation calculation for all
temp <- temp %>% mutate_if(is.numeric, ~cut(.,5))

#https://datascience.stackexchange.com/questions/893/how-to-get-correlation-between-two-categorical-variable-and-a-categorical-variab
cormat <- matrix(NA,ncol = ncol(temp),nrow=ncol(temp))
rownames(cormat) <-colnames(temp)
colnames(cormat) <-colnames(temp)
for (i in rownames(cormat)) {
  for (j in colnames(cormat)) {
    d <- table(as.factor(temp[[i]]),as.factor(temp[[j]]))
#    print(d)
    #drop any all zero rows
    d <- d[apply(X=d,MARGIN = 1,FUN = function(x){!all(x == 0 )}),]
    d <- d[,apply(X=d,MARGIN = 2,FUN = function(x){!all(x == 0 )})]
    #print(d)
    t <- chisq.test(d,correct = F)
    cramersV <- sqrt(t$statistic / sum(d))
    if (cramersV > 1) {
      #sometimes it fails in perfect correlation
      cramersV <- 1
    }
    cormat[i,j] <- cramersV
  }
}


```

Visualise correlation disribution
```{r}
temp <- data.frame(correlation=cormat[lower.tri(cormat)])
ggplot(temp) +  geom_histogram(aes(x=correlation),binwidth = 0.1)

#and create a fake significance matrix of arbitary correlation of 0.5
p.mat <- matrix(1, nrow=nrow(cormat),ncol=ncol(cormat))
p.mat[as.vector(cormat > 0.5)] <- 0.01 
diag(p.mat) <- 1

```


```{r}
corrplot(cormat,type="lower",order="hclust",p.mat=p.mat,sig.level = 0.05,insig = "label_sig",pch.col = 'red',pch.cex = 1)
```

Extract those with correlation above 0.5.
```{r}
#take anything with at least 0.5 correlation
any_above <- function(x){any(x > 0.5) }
temp <-cormat
#empty the diagonal
diag(temp) <- 0
#filter fake significance matrix
p.mat <- p.mat[apply(temp,1, any_above),apply(temp,2, any_above)]
#filter correlation matrix
temp <- temp[apply(temp,1, any_above),apply(temp,2, any_above)]
p.mat <- p.mat[apply(temp,1, any_above),apply(temp,2, any_above)]
corrplot(temp,type="lower",order="hclust",p.mat=p.mat,sig.level = 0.05,insig = "label_sig",pch.col = 'red',pch.cex = 1)
```

## act_light, act_heavy
```{r}
ggplot(data) + geom_bar(aes(x=act_light))
```

```{r}
ggplot(data) + geom_bar(aes(x=act_heavy))
```

```{r}
table(is.na(data$act_heavy))
table(is.na(data$act_light))
```
act_heavy looses more data, but has much more spread pontentially contaning more information.

Keep "act_heavy". 

##health_c vs phys_cond

```{r}
ggplot(data) + geom_bar(aes(x=health_c))
```
```{r}
ggplot(data) + geom_bar(aes(x=phys_cond))
```


```{r}
table(is.na(data$health_c))
table(is.na(data$phys_cond))
```


phys_cond looks better and looses less data. 

##vita_c vs vita_multi

```{r}
ggplot(data) + geom_bar(aes(x=vita_C))
```

```{r}
ggplot(data) + geom_bar(aes(x=vita_multi))
```

```{r}
table(is.na(data$vita_C))
table(is.na(data$vita_multi))
```


vita_multi looses much less data and looks better so vita_C can be dropped.

##sleep_night vs sleep_24h
```{r , warning=FALSE}
ggplot(data) + geom_histogram(aes(x=sleep_night),binwidth = 1)
```
```{r , warning=FALSE}
ggplot(data) + geom_histogram(aes(x=sleep_24h),binwidth = 1)
```

```{r}
table(is.na(data$sleep_night))
table(is.na(data$sleep_24h))
```

Distributions look quite similar, but sleep_night looses less data. 

##freq_fruits vs freq_vege
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=freq_fruits))
```
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=freq_vege))
```

```{r}
table(is.na(data$freq_fruits))
table(is.na(data$freq_vege))
```

freq_fruits look better and looses less data.

##freq_sports vs phys_cond
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=freq_sports))
```
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=phys_cond))
```

```{r}
table(is.na(data$freq_sports))
table(is.na(data$phys_cond))
```

Hard to say anything about the distributions, but physical condition looses less data.

##freq_spirits, freq_beer, freq_wine
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=freq_spirits))
```
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=freq_beer))
```
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=freq_wine))
```
```{r}
table(is.na(data$freq_spirits))
table(is.na(data$freq_beer))
table(is.na(data$freq_wine))
```
Hard to say, but freq_beer looses least data. But this does not cover at all persons that drink mostly cider which could be in particular found in pre-menopausal women.

To have have some kind of proxy over these incomplete but overlapping questions we will create a new variable freq_alc.

```{r}
#Combine the alcohol questions
data$freq_alc <- as.ordered(apply(cbind(data$freq_beer,data$freq_wine,data$freq_spirits),1,max,na.rm=TRUE))
#Make it in to a factor
levels(data$freq_alc) <- levels(data$freq_beer)

```


##freq_cutlets, freq_meat, diet, freq_meat, freq_fish, freq_eggs
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=freq_cutlets))
```
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=freq_red_meat))
```
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=diet))
```
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=freq_fish))
```
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=freq_eggs))
```

```{r}
table(is.na(data$freq_cutlets))
table(is.na(data$freq_red_meat))
table(is.na(data$diet))
table(is.na(data$freq_fish))
table(is.na(data$freq_eggs))
```

As already seen in the enrollment data paper freq_red_meats distribution looks best also it looses leas data.


##BMI, height and weigth
```{r , warning=FALSE}
ggplot(data) + geom_histogram(aes(x=BMI),binwidth = 1)
```
```{r , warning=FALSE}
ggplot(data) + geom_histogram(aes(x=height),binwidth = 5)
```

```{r , warning=FALSE}
ggplot(data) + geom_histogram(aes(x=weight),binwidth = 5)
```

```{r}
table(is.na(data$BMI))
table(is.na(data$height))
table(is.na(data$weight))
```

Keep BMI as composite of both.

##freq_energy, freq_sad, health_soc, freq_calm, accomplish
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=freq_energy))
```
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=freq_sad))
```
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=health_soc))
```
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=freq_calm))
```
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=accomplish))
```

```{r}
table(is.na(data$freq_energy))
table(is.na(data$freq_sad))
table(is.na(data$health_soc))
table(is.na(data$freq_calm))
table(is.na(data$accomplish))
```

accomplish looses a lot of data it can dropped just for that.
freq_energy correlates with phys_cond and can be dropped for that.
health_soc has a very skewed distiribution.
freq_calm looses least data and has maybe the best looking distribution.

##h_act_light vs h_act_noen
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=h_act_light))
```
```{r , warning=FALSE}
ggplot(data) + geom_bar(aes(x=h_act_none))
```

```{r}
table(is.na(data$h_act_light))
table(is.na(data$h_act_none))
```

h_act_light looses less data.

#Questions to drop
Based on the above we have decided to drop: act_light, health_c, vita_C, sleep_24h, freq_vege, freq_sports, freq_spirits, freq_beer, freq_wine, freq_cutlets, diet, freq_fish, freq_eggs, weight, height, accomplish, freq_energy, health_soc, freq_sad, h_act_none

```{r}
temp <- data %>% select(-iron_supp_detailed, -life_qual, -education, -employment,-AgeGroup, -SixMonthsFromStartCount_FB,-TwoYearsFromStartCount_FB,-donor, -act_light, -health_c, -vita_C, -sleep_24h, -freq_vege, -freq_sports, -freq_spirits, -freq_wine, -freq_beer, -freq_cutlets, -diet, -freq_fish, -freq_eggs, -weight, -height, -accomplish, -freq_energy, -health_soc, -freq_sad,-h_act_none)
temp <- na.omit(temp)
temp %>% group_by(questionnaire) %>% count()
```
From `r ncol(temp)` questions.

How will the sex/menopause groups look
```{r}
temp %>% group_by(questionnaire,group) %>% filter(group != 'Women_pre_menop_no_mens') %>%  count()
```

By excluding several questions that correlate with other questions and have distributions that are skewed (e.g. diet) or are uniformative (e.g. act_ligth)  or are not clearly ordered factors (like diet) we get complete data for about hundred more persons. `r ncol(temp)` might still be too many explenatory variables for the smallest group i.e. Post_menopause_women.

#Code answers as change

```{r}
#Extract complete data for both questinaires. 
```



```{r}
classes <- sort(unlist(lapply(lapply(temp,class),paste,collapse=" ")))
classes <- as.tibble(cbind(names(classes),classes))
```

```{r}
no_answers <- temp %>% summarise_all(~length(levels(.))) 
no_answers <- as_tibble(cbind(nms = names(no_answers), t(no_answers)))
no_answers <- full_join(no_answers,classes,by=c("nms"="V1"))
no_answers %>% group_by(V2) %>%  count()
```

```{r}
no_answers %>%  filter(V2 == 0)
```

```{r}
no_answers %>%  filter(V2 == 2)
```

```{r}
no_answers %>%  filter(V2 == 3)
```

```{r}
no_answers %>%  filter(V2 > 3)
```

temp %>% summarise_all(~length(levels(.))) 
